"""
åä½œç®¡ç†å™¨æ¨¡å—

å®ç°ç±»ä¼¼GitHubçš„å¤šæ™ºèƒ½ä½“åä½œæœºåˆ¶ï¼ŒåŒ…æ‹¬ï¼š
1. Pull Request æœºåˆ¶
2. ä»£ç å®¡æ ¸æµç¨‹
3. ä¸»ä»“åº“åä½œ
4. ä»£ç åŒæ­¥
"""

import os
import json
import logging
import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
from .git_utils import GitManager
from .llm_utils import LLMManager

logger = logging.getLogger(__name__)

class PullRequest:
    """Pull Request ç±»"""
    
    def __init__(self, pr_id: str, issue_id: str, author: str, title: str, 
                 description: str, code_changes: Dict[str, str], branch_name: str):
        self.pr_id = pr_id
        self.issue_id = issue_id
        self.author = author
        self.title = title
        self.description = description
        self.code_changes = code_changes  # {file_path: code_content}
        self.branch_name = branch_name
        self.status = "open"  # open, approved, rejected, merged
        self.created_at = datetime.now().isoformat()
        self.reviewed_at = None
        self.reviewer = None
        self.review_comments = []
        self.merge_commit = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "pr_id": self.pr_id,
            "issue_id": self.issue_id,
            "author": self.author,
            "title": self.title,
            "description": self.description,
            "code_changes": self.code_changes,
            "branch_name": self.branch_name,
            "status": self.status,
            "created_at": self.created_at,
            "reviewed_at": self.reviewed_at,
            "reviewer": self.reviewer,
            "review_comments": self.review_comments,
            "merge_commit": self.merge_commit
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'PullRequest':
        """ä»å­—å…¸åˆ›å»º"""
        pr = cls(
            data["pr_id"],
            data["issue_id"],
            data["author"],
            data["title"],
            data["description"],
            data["code_changes"],
            data["branch_name"]
        )
        pr.status = data.get("status", "open")
        pr.created_at = data.get("created_at", datetime.now().isoformat())
        pr.reviewed_at = data.get("reviewed_at")
        pr.reviewer = data.get("reviewer")
        pr.review_comments = data.get("review_comments", [])
        pr.merge_commit = data.get("merge_commit")
        return pr

class CollaborationManager:
    """åä½œç®¡ç†å™¨"""
    
    def __init__(self, main_repo_git_manager: GitManager, llm_manager: LLMManager):
        """åˆå§‹åŒ–åä½œç®¡ç†å™¨
        
        Args:
            main_repo_git_manager: ä¸»ä»“åº“çš„Gitç®¡ç†å™¨
            llm_manager: LLMç®¡ç†å™¨
        """
        self.main_repo_git_manager = main_repo_git_manager
        self.llm_manager = llm_manager
        self.pr_file_path = os.path.join(main_repo_git_manager.repo_path, ".pull_requests.json")
        self.agent_repos: Dict[str, GitManager] = {}
        
        # ç¡®ä¿PRæ–‡ä»¶å­˜åœ¨
        self._ensure_pr_file()
        logger.info("åˆå§‹åŒ–åä½œç®¡ç†å™¨")
    
    def _ensure_pr_file(self):
        """ç¡®ä¿PRæ–‡ä»¶å­˜åœ¨"""
        if not os.path.exists(self.pr_file_path):
            with open(self.pr_file_path, "w", encoding="utf-8") as f:
                json.dump({"pull_requests": []}, f, indent=2, ensure_ascii=False)
            logger.info("åˆ›å»ºPull Requestæ–‡ä»¶")
    
    def register_agent_repo(self, agent_id: str, git_manager: GitManager):
        """æ³¨å†Œagentä»“åº“
        
        Args:
            agent_id: agent ID
            git_manager: agentçš„Gitç®¡ç†å™¨
        """
        self.agent_repos[agent_id] = git_manager
        logger.info(f"æ³¨å†Œagentä»“åº“: {agent_id}")
    
    async def create_pull_request(self, issue_id: str, author: str, title: str, 
                                description: str, code_changes: Dict[str, str]) -> str:
        """åˆ›å»ºPull Request
        
        Args:
            issue_id: å…³è”çš„Issue ID
            author: ä½œè€…ï¼ˆagent IDï¼‰
            title: PRæ ‡é¢˜
            description: PRæè¿°
            code_changes: ä»£ç æ›´æ”¹ {file_path: code_content}
            
        Returns:
            PR ID
        """
        # ç”ŸæˆPR ID
        pr_id = f"pr_{issue_id}_{author}_{int(datetime.now().timestamp())}"
        branch_name = f"feature/{issue_id}-{author}"
        
        # åˆ›å»ºPRå¯¹è±¡
        pr = PullRequest(
            pr_id=pr_id,
            issue_id=issue_id,
            author=author,
            title=title,
            description=description,
            code_changes=code_changes,
            branch_name=branch_name
        )
        
        # åœ¨authorçš„ä»“åº“ä¸­åˆ›å»ºåˆ†æ”¯
        if author in self.agent_repos:
            agent_git = self.agent_repos[author]
            try:
                # åˆ›å»ºå¹¶åˆ‡æ¢åˆ°æ–°åˆ†æ”¯
                await agent_git.create_branch(branch_name)
                logger.info(f"ä¸º{author}åˆ›å»ºåˆ†æ”¯: {branch_name}")
                
                # åœ¨åˆ†æ”¯ä¸­æäº¤ä»£ç æ›´æ”¹
                for file_path, code_content in code_changes.items():
                    full_path = os.path.join(agent_git.repo_path, file_path)
                    os.makedirs(os.path.dirname(full_path), exist_ok=True)
                    
                    with open(full_path, "w", encoding="utf-8") as f:
                        f.write(code_content)
                
                # æäº¤æ›´æ”¹
                commit_message = f"feat: {title}\n\nImplements #{issue_id}\n\nPR: #{pr_id}"
                await agent_git.commit_changes(commit_message, list(code_changes.keys()))
                logger.info(f"{author}åœ¨åˆ†æ”¯{branch_name}ä¸­æäº¤ä»£ç ")
                
            except Exception as e:
                logger.error(f"åœ¨agentä»“åº“ä¸­åˆ›å»ºåˆ†æ”¯å¤±è´¥: {e}")
        
        # ä¿å­˜PRåˆ°æ–‡ä»¶
        await self._save_pull_request(pr)
        
        logger.info(f"ğŸ”„ åˆ›å»ºPull Request: {pr_id} by {author}")
        logger.info(f"ğŸ“‹ PRæ ‡é¢˜: {title}")
        logger.info(f"ğŸŒ¿ åˆ†æ”¯: {branch_name}")
        logger.info(f"ğŸ“ æ–‡ä»¶æ•°é‡: {len(code_changes)}")
        
        return pr_id
    
    async def _save_pull_request(self, pr: PullRequest):
        """ä¿å­˜PRåˆ°æ–‡ä»¶"""
        try:
            # è¯»å–ç°æœ‰PR
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # æ›´æ–°æˆ–æ·»åŠ PR
            prs = data.get("pull_requests", [])
            existing_pr_index = None
            for i, existing_pr in enumerate(prs):
                if existing_pr["pr_id"] == pr.pr_id:
                    existing_pr_index = i
                    break
            
            if existing_pr_index is not None:
                prs[existing_pr_index] = pr.to_dict()
            else:
                prs.append(pr.to_dict())
            
            data["pull_requests"] = prs
            
            # å†™å›æ–‡ä»¶
            with open(self.pr_file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # æäº¤PRæ–‡ä»¶æ›´æ”¹åˆ°ä¸»ä»“åº“
            await self.main_repo_git_manager.commit_changes(
                f"Update PR: {pr.pr_id}",
                [".pull_requests.json"]
            )
            
        except Exception as e:
            logger.error(f"ä¿å­˜PRå¤±è´¥: {e}")
    
    async def get_open_pull_requests(self) -> List[PullRequest]:
        """è·å–å¼€æ”¾çš„Pull Request"""
        try:
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            prs = []
            for pr_data in data.get("pull_requests", []):
                if pr_data.get("status") == "open":
                    prs.append(PullRequest.from_dict(pr_data))
            
            return prs
        except Exception as e:
            logger.error(f"è·å–å¼€æ”¾PRå¤±è´¥: {e}")
            return []
    
    async def review_pull_request(self, pr_id: str, reviewer: str, 
                                approved: bool, comments: str = "") -> bool:
        """å®¡æ ¸Pull Request
        
        Args:
            pr_id: PR ID
            reviewer: å®¡æ ¸è€…
            approved: æ˜¯å¦é€šè¿‡
            comments: å®¡æ ¸è¯„è®º
            
        Returns:
            æ˜¯å¦å®¡æ ¸æˆåŠŸ
        """
        try:
            # è¯»å–PR
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # æ‰¾åˆ°å¯¹åº”çš„PR
            prs = data.get("pull_requests", [])
            pr_data = None
            pr_index = None
            
            for i, pr in enumerate(prs):
                if pr["pr_id"] == pr_id:
                    pr_data = pr
                    pr_index = i
                    break
            
            if not pr_data:
                logger.error(f"æœªæ‰¾åˆ°PR: {pr_id}")
                return False
            
            # æ›´æ–°PRçŠ¶æ€
            pr_data["status"] = "approved" if approved else "rejected"
            pr_data["reviewed_at"] = datetime.now().isoformat()
            pr_data["reviewer"] = reviewer
            pr_data["review_comments"].append({
                "reviewer": reviewer,
                "approved": approved,
                "comments": comments,
                "timestamp": datetime.now().isoformat()
            })
            
            prs[pr_index] = pr_data
            data["pull_requests"] = prs
            
            # ä¿å­˜æ›´æ”¹
            with open(self.pr_file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            # æäº¤æ›´æ”¹
            await self.main_repo_git_manager.commit_changes(
                f"Review PR {pr_id}: {'approved' if approved else 'rejected'}",
                [".pull_requests.json"]
            )
            
            logger.info(f"{'âœ…' if approved else 'âŒ'} PR {pr_id} å®¡æ ¸{'é€šè¿‡' if approved else 'æœªé€šè¿‡'}")
            logger.info(f"ğŸ‘¤ å®¡æ ¸è€…: {reviewer}")
            if comments:
                logger.info(f"ğŸ’¬ è¯„è®º: {comments}")
            
            # å¦‚æœé€šè¿‡å®¡æ ¸ï¼Œè‡ªåŠ¨åˆå¹¶
            if approved:
                await self.merge_pull_request(pr_id)
            
            return True
            
        except Exception as e:
            logger.error(f"å®¡æ ¸PRå¤±è´¥: {e}")
            return False
    
    async def merge_pull_request(self, pr_id: str) -> bool:
        """åˆå¹¶Pull Requeståˆ°ä¸»ä»“åº“
        
        Args:
            pr_id: PR ID
            
        Returns:
            æ˜¯å¦åˆå¹¶æˆåŠŸ
        """
        try:
            # è¯»å–PR
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            # æ‰¾åˆ°å¯¹åº”çš„PR
            pr_data = None
            pr_index = None
            
            for i, pr in enumerate(data.get("pull_requests", [])):
                if pr["pr_id"] == pr_id:
                    pr_data = pr
                    pr_index = i
                    break
            
            if not pr_data or pr_data["status"] != "approved":
                logger.error(f"PR {pr_id} æœªæ‰¾åˆ°æˆ–æœªé€šè¿‡å®¡æ ¸")
                return False
            
            # å°†ä»£ç æ›´æ”¹åº”ç”¨åˆ°ä¸»ä»“åº“
            logger.info(f"ğŸ”€ å¼€å§‹åˆå¹¶PR {pr_id} åˆ°ä¸»ä»“åº“")
            
            for file_path, code_content in pr_data["code_changes"].items():
                full_path = os.path.join(self.main_repo_git_manager.repo_path, file_path)
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                
                with open(full_path, "w", encoding="utf-8") as f:
                    f.write(code_content)
                
                logger.info(f"ğŸ“ åˆå¹¶æ–‡ä»¶: {file_path}")
            
            # æäº¤åˆå¹¶
            merge_message = f"Merge PR #{pr_id}: {pr_data['title']}\n\nCloses #{pr_data['issue_id']}"
            commit_hash = await self.main_repo_git_manager.commit_changes(
                merge_message,
                list(pr_data["code_changes"].keys())
            )
            
            # æ›´æ–°PRçŠ¶æ€
            pr_data["status"] = "merged"
            pr_data["merge_commit"] = commit_hash
            data["pull_requests"][pr_index] = pr_data
            
            # ä¿å­˜PRæ›´æ”¹
            with open(self.pr_file_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
            
            await self.main_repo_git_manager.commit_changes(
                f"Update PR {pr_id} status to merged",
                [".pull_requests.json"]
            )
            
            logger.info(f"ğŸ‰ PR {pr_id} æˆåŠŸåˆå¹¶åˆ°ä¸»ä»“åº“")
            logger.info(f"ğŸ“ åˆå¹¶æäº¤: {commit_hash}")
            
            # é€šçŸ¥æ‰€æœ‰agentåŒæ­¥ä»£ç 
            await self.sync_all_agents()
            
            return True
            
        except Exception as e:
            logger.error(f"åˆå¹¶PRå¤±è´¥: {e}")
            return False
    
    async def sync_all_agents(self):
        """åŒæ­¥æ‰€æœ‰agentçš„ä»£ç """
        logger.info("ğŸ”„ å¼€å§‹åŒæ­¥æ‰€æœ‰agentçš„ä»£ç ...")
        
        for agent_id, agent_git in self.agent_repos.items():
            try:
                logger.info(f"ğŸ“¥ åŒæ­¥agent {agent_id} çš„ä»£ç ")
                
                # æ£€æŸ¥å½“å‰åˆ†æ”¯å’Œå·¥ä½œç›®å½•çŠ¶æ€
                current_branch = await agent_git.get_current_branch()
                logger.debug(f"ğŸŒ¿ agent {agent_id} å½“å‰åˆ†æ”¯: {current_branch}")
                
                # ç¡®ä¿mainåˆ†æ”¯å­˜åœ¨
                branches = await agent_git.list_branches()
                if "main" not in branches:
                    logger.info(f"ğŸ†• ä¸ºagent {agent_id} åˆ›å»ºmainåˆ†æ”¯")
                    # å¦‚æœæ²¡æœ‰mainåˆ†æ”¯ï¼Œåˆ›å»ºä¸€ä¸ª
                    try:
                        # å…ˆç¡®ä¿æœ‰åˆå§‹æäº¤
                        readme_path = os.path.join(agent_git.repo_path, "README.md")
                        if not os.path.exists(readme_path):
                            with open(readme_path, "w", encoding="utf-8") as f:
                                f.write(f"# Agent {agent_id} Repository\n\nThis is the working repository for agent {agent_id}.\n")
                            await agent_git.commit_changes("Initial commit", ["README.md"])
                        
                        # åˆ›å»ºmainåˆ†æ”¯
                        await agent_git.create_branch("main")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ›å»ºmainåˆ†æ”¯å¤±è´¥: {e}")
                
                # å¦‚æœä¸åœ¨mainåˆ†æ”¯ï¼Œéœ€è¦å®‰å…¨åœ°åˆ‡æ¢
                if current_branch != "main":
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹
                    try:
                        # å…ˆæš‚å­˜æ‰€æœ‰æ›´æ”¹
                        agent_git.repo.git.stash("push", "--include-untracked", "-m", f"Auto stash before sync")
                        logger.debug(f"ğŸ’¾ ä¸ºagent {agent_id} æš‚å­˜æœªæäº¤çš„æ›´æ”¹")
                    except Exception as e:
                        logger.debug(f"æš‚å­˜æ›´æ”¹å¤±è´¥æˆ–æ— æ›´æ”¹éœ€è¦æš‚å­˜: {e}")
                    
                    # åˆ‡æ¢åˆ°mainåˆ†æ”¯
                    success = await agent_git.checkout_branch("main")
                    if not success:
                        logger.warning(f"âš ï¸ agent {agent_id} åˆ‡æ¢åˆ°mainåˆ†æ”¯å¤±è´¥ï¼Œè·³è¿‡åŒæ­¥")
                        continue
                
                # ä»ä¸»ä»“åº“æ‹‰å–æœ€æ–°ä»£ç 
                await self._sync_from_main_repo(agent_git)
                
                logger.info(f"âœ… agent {agent_id} åŒæ­¥å®Œæˆ")
                
            except Exception as e:
                logger.error(f"âŒ åŒæ­¥agent {agent_id} å¤±è´¥: {e}")
                import traceback
                logger.debug(f"ğŸ” åŒæ­¥é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
    
    async def _sync_from_main_repo(self, agent_git: GitManager):
        """ä»ä¸»ä»“åº“åŒæ­¥ä»£ç åˆ°agentä»“åº“"""
        try:
            # è·å–ä¸»ä»“åº“ä¸­çš„æ‰€æœ‰éGitæ–‡ä»¶
            import shutil
            import fnmatch
            
            # å®šä¹‰è¦å¿½ç•¥çš„æ–‡ä»¶å’Œç›®å½•æ¨¡å¼
            ignore_patterns = [
                '.git*',
                '__pycache__',
                '*.pyc',
                '*.pyo',
                '.DS_Store',
                'Thumbs.db'
            ]
            
            def should_ignore(path):
                """æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥æŸä¸ªè·¯å¾„"""
                basename = os.path.basename(path)
                for pattern in ignore_patterns:
                    if fnmatch.fnmatch(basename, pattern):
                        return True
                return False
            
            # åŒæ­¥æ–‡ä»¶
            synced_files = []
            
            for root, dirs, files in os.walk(self.main_repo_git_manager.repo_path):
                # è¿‡æ»¤è¦å¿½ç•¥çš„ç›®å½•
                dirs[:] = [d for d in dirs if not should_ignore(os.path.join(root, d))]
                
                for file in files:
                    src_file = os.path.join(root, file)
                    
                    # è·³è¿‡è¦å¿½ç•¥çš„æ–‡ä»¶
                    if should_ignore(src_file):
                        continue
                    
                    # è®¡ç®—ç›¸å¯¹è·¯å¾„
                    rel_path = os.path.relpath(src_file, self.main_repo_git_manager.repo_path)
                    dst_file = os.path.join(agent_git.repo_path, rel_path)
                    
                    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                    dst_dir = os.path.dirname(dst_file)
                    if dst_dir:
                        os.makedirs(dst_dir, exist_ok=True)
                    
                    try:
                        # å¤åˆ¶æ–‡ä»¶
                        shutil.copy2(src_file, dst_file)
                        synced_files.append(rel_path)
                        logger.debug(f"ğŸ“„ åŒæ­¥æ–‡ä»¶: {rel_path}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {rel_path}: {e}")
            
            if synced_files:
                logger.info(f"ğŸ“¦ åŒæ­¥äº† {len(synced_files)} ä¸ªæ–‡ä»¶")
                
                # æäº¤åŒæ­¥çš„æ›´æ”¹
                commit_hash = await agent_git.commit_changes(
                    "Sync from main repository",
                    ["."]  # æ·»åŠ æ‰€æœ‰æ›´æ”¹
                )
                
                if commit_hash:
                    logger.debug(f"âœ… åŒæ­¥æäº¤: {commit_hash[:8]}")
                else:
                    logger.debug("ğŸ“ æ²¡æœ‰éœ€è¦æäº¤çš„æ›´æ”¹")
            else:
                logger.debug("ğŸ“­ æ²¡æœ‰æ–‡ä»¶éœ€è¦åŒæ­¥")
            
        except Exception as e:
            logger.error(f"ä»ä¸»ä»“åº“åŒæ­¥å¤±è´¥: {e}")
            import traceback
            logger.debug(f"ğŸ” åŒæ­¥é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
    
    async def get_pr_by_id(self, pr_id: str) -> Optional[PullRequest]:
        """æ ¹æ®IDè·å–PR"""
        try:
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            for pr_data in data.get("pull_requests", []):
                if pr_data["pr_id"] == pr_id:
                    return PullRequest.from_dict(pr_data)
            
            return None
        except Exception as e:
            logger.error(f"è·å–PRå¤±è´¥: {e}")
            return None
    
    async def cleanup_merged_branches(self):
        """æ¸…ç†å·²åˆå¹¶çš„åˆ†æ”¯"""
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†å·²åˆå¹¶çš„åˆ†æ”¯...")
        
        try:
            with open(self.pr_file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            for pr_data in data.get("pull_requests", []):
                if pr_data["status"] == "merged":
                    author = pr_data["author"]
                    branch_name = pr_data["branch_name"]
                    
                    if author in self.agent_repos:
                        try:
                            agent_git = self.agent_repos[author]
                            await agent_git.delete_branch(branch_name)
                            logger.info(f"ğŸ—‘ï¸ åˆ é™¤å·²åˆå¹¶åˆ†æ”¯: {branch_name}")
                        except Exception as e:
                            logger.debug(f"åˆ é™¤åˆ†æ”¯å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"æ¸…ç†åˆ†æ”¯å¤±è´¥: {e}") 