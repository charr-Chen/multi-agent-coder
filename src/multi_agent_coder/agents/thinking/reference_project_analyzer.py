"""
å‚è€ƒé¡¹ç›®åˆ†æå™¨

è´Ÿè´£åˆ†æç”¨æˆ·ä¼ å…¥çš„å‚è€ƒé¡¹ç›®ï¼Œæå–å…³é”®çš„ä»£ç æ¨¡å¼ã€æ¶æ„é£æ ¼ã€
æœ€ä½³å®è·µç­‰ä¿¡æ¯ï¼Œç”¨äºæŒ‡å¯¼åç»­çš„ä»£ç ç”Ÿæˆã€‚
"""

import os
import ast
import json
import logging
import asyncio
from pathlib import Path
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Optional, Set

logger = logging.getLogger(__name__)


class ArchitecturePattern(Enum):
    """æ¶æ„æ¨¡å¼æšä¸¾"""
    MVC = "mvc"
    MICROSERVICES = "microservices"
    LAYERED = "layered"
    CLEAN_ARCHITECTURE = "clean_architecture"
    EVENT_DRIVEN = "event_driven"
    PLUGIN = "plugin"
    MONOLITHIC = "monolithic"


class FrameworkType(Enum):
    """æ¡†æ¶ç±»å‹æšä¸¾"""
    FASTAPI = "fastapi"
    DJANGO = "django"
    FLASK = "flask"
    STREAMLIT = "streamlit"
    TKINTER = "tkinter"
    PYTEST = "pytest"
    LANGCHAIN = "langchain"
    PYDANTIC = "pydantic"
    SQLALCHEMY = "sqlalchemy"


@dataclass
class CodePattern:
    """ä»£ç æ¨¡å¼æ•°æ®ç±»"""
    pattern_type: str
    description: str
    example_code: str
    file_path: str
    frequency: int = 1


@dataclass
class ProjectStructure:
    """é¡¹ç›®ç»“æ„æ•°æ®ç±»"""
    directories: list[str]
    main_modules: list[str]
    config_files: list[str]
    test_directories: list[str]
    documentation_files: list[str]


@dataclass
class CodingStyle:
    """ç¼–ç é£æ ¼æ•°æ®ç±»"""
    naming_conventions: dict[str, str]
    import_patterns: list[str]
    error_handling_patterns: list[str]
    documentation_style: str
    type_hints_usage: bool
    async_patterns: list[str]


@dataclass
class TechStack:
    """æŠ€æœ¯æ ˆæ•°æ®ç±»"""
    frameworks: list[FrameworkType]
    dependencies: dict[str, str]
    python_version: Optional[str]
    architecture_patterns: list[ArchitecturePattern]


@dataclass
class ReferenceProjectAnalysis:
    """å‚è€ƒé¡¹ç›®åˆ†æç»“æœ"""
    project_name: str
    project_path: str
    tech_stack: TechStack
    project_structure: ProjectStructure
    coding_style: CodingStyle
    code_patterns: list[CodePattern]
    best_practices: list[str]
    common_utilities: list[str]
    api_patterns: list[str]
    error_handling_strategies: list[str]
    testing_patterns: list[str]
    deployment_patterns: list[str]


class ReferenceProjectAnalyzer:
    """å‚è€ƒé¡¹ç›®åˆ†æå™¨"""
    
    def __init__(self, workspace_root: str):
        self.workspace_root = Path(workspace_root)
        self.supported_extensions = {'.py', '.yaml', '.yml', '.json', '.toml', '.md', '.txt'}
        
    def detect_reference_projects(self) -> list[str]:
        """æ£€æµ‹å·¥ä½œç©ºé—´ä¸­çš„å‚è€ƒé¡¹ç›®"""
        reference_projects = []
        
        for item in self.workspace_root.iterdir():
            if item.is_dir() and item.name not in {'.git', '.venv', '__pycache__', 'node_modules', 'agent_repos', 'src', '.memory'}:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Pythoné¡¹ç›®
                if self._is_valid_python_project(item):
                    reference_projects.append(item.name)
                    logger.info(f"ğŸ” æ£€æµ‹åˆ°å‚è€ƒé¡¹ç›®: {item.name}")
        
        return reference_projects
    
    def _is_valid_python_project(self, project_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Pythoné¡¹ç›®"""
        # æ£€æŸ¥å¸¸è§çš„Pythoné¡¹ç›®æ ‡è¯†æ–‡ä»¶
        indicators = [
            'setup.py', 'pyproject.toml', 'requirements.txt', 
            'Pipfile', 'poetry.lock', 'environment.yml'
        ]
        
        for indicator in indicators:
            if (project_path / indicator).exists():
                return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Pythonæ–‡ä»¶
        python_files = list(project_path.rglob('*.py'))
        return len(python_files) > 0
    
    async def analyze_project(self, project_name: str) -> ReferenceProjectAnalysis:
        """åˆ†ææŒ‡å®šçš„å‚è€ƒé¡¹ç›®"""
        project_path = self.workspace_root / project_name
        
        if not project_path.exists():
            raise ValueError(f"å‚è€ƒé¡¹ç›®ä¸å­˜åœ¨: {project_name}")
        
        logger.info(f"ğŸ” å¼€å§‹åˆ†æå‚è€ƒé¡¹ç›®: {project_name}")
        
        # åˆ†æé¡¹ç›®ç»“æ„
        project_structure = self._analyze_project_structure(project_path)
        
        # åˆ†ææŠ€æœ¯æ ˆ
        tech_stack = self._analyze_tech_stack(project_path)
        
        # åˆ†æç¼–ç é£æ ¼
        coding_style = await self._analyze_coding_style(project_path)
        
        # æå–ä»£ç æ¨¡å¼
        code_patterns = await self._extract_code_patterns(project_path)
        
        # åˆ†ææœ€ä½³å®è·µ
        best_practices = self._analyze_best_practices(project_path, code_patterns)
        
        # åˆ†æå¸¸ç”¨å·¥å…·
        common_utilities = self._extract_common_utilities(project_path)
        
        # åˆ†æAPIæ¨¡å¼
        api_patterns = self._extract_api_patterns(project_path)
        
        # åˆ†æé”™è¯¯å¤„ç†ç­–ç•¥
        error_handling = self._extract_error_handling_strategies(project_path)
        
        # åˆ†ææµ‹è¯•æ¨¡å¼
        testing_patterns = self._extract_testing_patterns(project_path)
        
        # åˆ†æéƒ¨ç½²æ¨¡å¼
        deployment_patterns = self._extract_deployment_patterns(project_path)
        
        analysis = ReferenceProjectAnalysis(
            project_name=project_name,
            project_path=str(project_path),
            tech_stack=tech_stack,
            project_structure=project_structure,
            coding_style=coding_style,
            code_patterns=code_patterns,
            best_practices=best_practices,
            common_utilities=common_utilities,
            api_patterns=api_patterns,
            error_handling_strategies=error_handling,
            testing_patterns=testing_patterns,
            deployment_patterns=deployment_patterns
        )
        
        logger.info(f"âœ… å®Œæˆå‚è€ƒé¡¹ç›®åˆ†æ: {project_name}")
        return analysis
    
    def _analyze_project_structure(self, project_path: Path) -> ProjectStructure:
        """åˆ†æé¡¹ç›®ç»“æ„"""
        directories = []
        main_modules = []
        config_files = []
        test_directories = []
        documentation_files = []
        
        for root, dirs, files in os.walk(project_path):
            root_path = Path(root)
            relative_path = root_path.relative_to(project_path)
            
            # è·³è¿‡éšè—ç›®å½•å’Œè™šæ‹Ÿç¯å¢ƒ
            if any(part.startswith('.') or part in {'__pycache__', 'node_modules'} for part in relative_path.parts):
                continue
            
            directories.append(str(relative_path))
            
            # è¯†åˆ«æµ‹è¯•ç›®å½•
            if any(keyword in str(relative_path).lower() for keyword in ['test', 'tests']):
                test_directories.append(str(relative_path))
            
            for file in files:
                file_path = root_path / file
                relative_file_path = file_path.relative_to(project_path)
                
                # é…ç½®æ–‡ä»¶
                if file in ['setup.py', 'pyproject.toml', 'requirements.txt', 'Dockerfile', 'docker-compose.yml']:
                    config_files.append(str(relative_file_path))
                
                # æ–‡æ¡£æ–‡ä»¶
                elif file.lower().endswith(('.md', '.rst', '.txt')) and any(keyword in file.lower() for keyword in ['readme', 'doc', 'guide']):
                    documentation_files.append(str(relative_file_path))
                
                # ä¸»è¦æ¨¡å—ï¼ˆPythonæ–‡ä»¶ï¼‰
                elif file.endswith('.py') and not file.startswith('test_'):
                    if file in ['__init__.py', 'main.py', 'app.py', 'server.py']:
                        main_modules.append(str(relative_file_path))
        
        return ProjectStructure(
            directories=directories[:20],  # é™åˆ¶æ•°é‡
            main_modules=main_modules,
            config_files=config_files,
            test_directories=test_directories,
            documentation_files=documentation_files
        )
    
    def _analyze_tech_stack(self, project_path: Path) -> TechStack:
        """åˆ†ææŠ€æœ¯æ ˆ"""
        frameworks = []
        dependencies = {}
        python_version = None
        architecture_patterns = []
        
        # åˆ†æä¾èµ–æ–‡ä»¶
        deps = self._parse_dependencies(project_path)
        dependencies.update(deps)
        
        # æ£€æµ‹æ¡†æ¶
        for dep, version in deps.items():
            dep_lower = dep.lower()
            if 'fastapi' in dep_lower:
                frameworks.append(FrameworkType.FASTAPI)
            elif 'django' in dep_lower:
                frameworks.append(FrameworkType.DJANGO)
            elif 'flask' in dep_lower:
                frameworks.append(FrameworkType.FLASK)
            elif 'streamlit' in dep_lower:
                frameworks.append(FrameworkType.STREAMLIT)
            elif 'pytest' in dep_lower:
                frameworks.append(FrameworkType.PYTEST)
            elif 'langchain' in dep_lower:
                frameworks.append(FrameworkType.LANGCHAIN)
            elif 'pydantic' in dep_lower:
                frameworks.append(FrameworkType.PYDANTIC)
            elif 'sqlalchemy' in dep_lower:
                frameworks.append(FrameworkType.SQLALCHEMY)
        
        # æ£€æµ‹æ¶æ„æ¨¡å¼
        architecture_patterns = self._detect_architecture_patterns(project_path)
        
        # æ£€æµ‹Pythonç‰ˆæœ¬
        python_version = self._detect_python_version(project_path)
        
        return TechStack(
            frameworks=frameworks,
            dependencies=dependencies,
            python_version=python_version,
            architecture_patterns=architecture_patterns
        )
    
    def _parse_dependencies(self, project_path: Path) -> dict[str, str]:
        """è§£æä¾èµ–æ–‡ä»¶"""
        dependencies = {}
        
        # åœ¨é¡¹ç›®æ ¹ç›®å½•å’Œä¸»è¦å­ç›®å½•ä¸­æŸ¥æ‰¾ä¾èµ–æ–‡ä»¶
        search_paths = [project_path]
        
        # æ·»åŠ å¸¸è§çš„å­é¡¹ç›®ç›®å½•
        for subdir in ['platform', 'backend', 'api', 'server', 'src']:
            subpath = project_path / subdir
            if subpath.exists() and subpath.is_dir():
                search_paths.append(subpath)
        
        for search_path in search_paths:
            # requirements.txt
            req_file = search_path / 'requirements.txt'
            if req_file.exists():
                try:
                    content = req_file.read_text()
                    for line in content.splitlines():
                        line = line.strip()
                        if line and not line.startswith('#'):
                            if '==' in line:
                                name, version = line.split('==', 1)
                                dependencies[name.strip()] = version.strip()
                            elif '>=' in line:
                                name = line.split('>=')[0].strip()
                                dependencies[name] = 'latest'
                            else:
                                dependencies[line] = 'latest'
                except Exception as e:
                    logger.warning(f"è§£ærequirements.txtå¤±è´¥: {e}")
            
            # pyproject.toml
            pyproject_file = search_path / 'pyproject.toml'
            if pyproject_file.exists():
                try:
                    import toml
                    data = toml.load(pyproject_file)
                    
                    # æ”¯æŒPoetryæ ¼å¼: [tool.poetry.dependencies]
                    poetry_deps = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
                    for name, version_spec in poetry_deps.items():
                        if name != 'python':  # è·³è¿‡pythonç‰ˆæœ¬çº¦æŸ
                            if isinstance(version_spec, str):
                                # å¤„ç† "^0.98.0" æ ¼å¼
                                version = version_spec.lstrip('^~>=<')
                                dependencies[name] = version
                            elif hasattr(version_spec, 'get'):  # å¤„ç†å­—å…¸æˆ–ç±»å­—å…¸å¯¹è±¡
                                # å¤„ç† { version = "^0.22.0", extras = ["standard"] } æ ¼å¼
                                version = version_spec.get('version', 'latest')
                                if isinstance(version, str):
                                    dependencies[name] = version.lstrip('^~>=<')
                                else:
                                    dependencies[name] = 'latest'
                    
                    # æ”¯æŒæ ‡å‡†æ ¼å¼: [project.dependencies]
                    if 'dependencies' in data.get('project', {}):
                        for dep in data['project']['dependencies']:
                            if '==' in dep:
                                name, version = dep.split('==', 1)
                                dependencies[name.strip()] = version.strip()
                            else:
                                dependencies[dep] = 'latest'
                                
                except Exception as e:
                    logger.warning(f"è§£æpyproject.tomlå¤±è´¥ ({search_path}): {e}")
        
        return dependencies
    
    def _detect_architecture_patterns(self, project_path: Path) -> list[ArchitecturePattern]:
        """æ£€æµ‹æ¶æ„æ¨¡å¼"""
        patterns = []
        
        # æ£€æŸ¥ç›®å½•ç»“æ„æ¥æ¨æ–­æ¶æ„æ¨¡å¼
        dirs = [d.name for d in project_path.iterdir() if d.is_dir()]
        
        # å¾®æœåŠ¡æ¶æ„
        if any(keyword in ' '.join(dirs).lower() for keyword in ['service', 'api', 'microservice']):
            patterns.append(ArchitecturePattern.MICROSERVICES)
        
        # MVCæ¨¡å¼
        if any(keyword in ' '.join(dirs).lower() for keyword in ['model', 'view', 'controller']):
            patterns.append(ArchitecturePattern.MVC)
        
        # åˆ†å±‚æ¶æ„
        if any(keyword in ' '.join(dirs).lower() for keyword in ['domain', 'application', 'infrastructure']):
            patterns.append(ArchitecturePattern.LAYERED)
        
        # æ¸…æ´æ¶æ„
        if any(keyword in ' '.join(dirs).lower() for keyword in ['use_case', 'entity', 'adapter']):
            patterns.append(ArchitecturePattern.CLEAN_ARCHITECTURE)
        
        # æ’ä»¶æ¶æ„
        if any(keyword in ' '.join(dirs).lower() for keyword in ['plugin', 'extension']):
            patterns.append(ArchitecturePattern.PLUGIN)
        
        return patterns if patterns else [ArchitecturePattern.MONOLITHIC]
    
    def _detect_python_version(self, project_path: Path) -> Optional[str]:
        """æ£€æµ‹Pythonç‰ˆæœ¬"""
        # åœ¨é¡¹ç›®æ ¹ç›®å½•å’Œä¸»è¦å­ç›®å½•ä¸­æŸ¥æ‰¾Pythonç‰ˆæœ¬ä¿¡æ¯
        search_paths = [project_path]
        
        # æ·»åŠ å¸¸è§çš„å­é¡¹ç›®ç›®å½•
        for subdir in ['platform', 'backend', 'api', 'server', 'src']:
            subpath = project_path / subdir
            if subpath.exists() and subpath.is_dir():
                search_paths.append(subpath)
        
        for search_path in search_paths:
            # ä»pyproject.tomlæ£€æµ‹
            pyproject_file = search_path / 'pyproject.toml'
            if pyproject_file.exists():
                try:
                    import toml
                    data = toml.load(pyproject_file)
                    
                    # Poetryæ ¼å¼
                    poetry_python = data.get('tool', {}).get('poetry', {}).get('dependencies', {}).get('python')
                    if poetry_python:
                        return poetry_python
                    
                    # æ ‡å‡†æ ¼å¼
                    python_req = data.get('project', {}).get('requires-python')
                    if python_req:
                        return python_req
                except Exception:
                    continue
            
            # ä».python-versionæ£€æµ‹
            python_version_file = search_path / '.python-version'
            if python_version_file.exists():
                try:
                    return python_version_file.read_text().strip()
                except Exception:
                    continue
        
        return None
    
    async def _analyze_coding_style(self, project_path: Path) -> CodingStyle:
        """åˆ†æç¼–ç é£æ ¼"""
        naming_conventions = {}
        import_patterns = []
        error_handling_patterns = []
        documentation_style = "google"  # é»˜è®¤
        type_hints_usage = False
        async_patterns = []
        
        # åˆ†æPythonæ–‡ä»¶
        python_files = list(project_path.rglob('*.py'))[:50]  # é™åˆ¶æ–‡ä»¶æ•°é‡
        
        for py_file in python_files:
            try:
                content = py_file.read_text(encoding='utf-8')
                tree = ast.parse(content)
                
                # åˆ†æå‘½åçº¦å®š
                self._analyze_naming_conventions(tree, naming_conventions)
                
                # åˆ†æå¯¼å…¥æ¨¡å¼
                self._analyze_import_patterns(content, import_patterns)
                
                # åˆ†æé”™è¯¯å¤„ç†
                self._analyze_error_handling(tree, error_handling_patterns)
                
                # æ£€æŸ¥ç±»å‹æç¤º
                if self._has_type_hints(tree):
                    type_hints_usage = True
                
                # æ£€æŸ¥å¼‚æ­¥æ¨¡å¼
                self._analyze_async_patterns(tree, async_patterns)
                
            except Exception as e:
                logger.warning(f"åˆ†ææ–‡ä»¶ {py_file} å¤±è´¥: {e}")
                continue
        
        return CodingStyle(
            naming_conventions=naming_conventions,
            import_patterns=list(set(import_patterns)),
            error_handling_patterns=list(set(error_handling_patterns)),
            documentation_style=documentation_style,
            type_hints_usage=type_hints_usage,
            async_patterns=list(set(async_patterns))
        )
    
    def _analyze_naming_conventions(self, tree: ast.AST, conventions: dict[str, str]):
        """åˆ†æå‘½åçº¦å®š"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                if re.match(r'^[A-Z][a-zA-Z0-9]*$', node.name):
                    conventions['class'] = 'PascalCase'
            elif isinstance(node, ast.FunctionDef):
                if re.match(r'^[a-z_][a-z0-9_]*$', node.name):
                    conventions['function'] = 'snake_case'
            elif isinstance(node, ast.Name) and isinstance(node.ctx, ast.Store):
                if re.match(r'^[a-z_][a-z0-9_]*$', node.id):
                    conventions['variable'] = 'snake_case'
                elif re.match(r'^[A-Z_][A-Z0-9_]*$', node.id):
                    conventions['constant'] = 'UPPER_SNAKE_CASE'
    
    def _analyze_import_patterns(self, content: str, patterns: list[str]):
        """åˆ†æå¯¼å…¥æ¨¡å¼"""
        lines = content.splitlines()
        for line in lines:
            line = line.strip()
            if line.startswith('from ') and ' import ' in line:
                patterns.append('relative_import')
            elif line.startswith('import '):
                patterns.append('absolute_import')
            elif re.match(r'from \. import', line):
                patterns.append('package_relative_import')
    
    def _analyze_error_handling(self, tree: ast.AST, patterns: list[str]):
        """åˆ†æé”™è¯¯å¤„ç†æ¨¡å¼"""
        for node in ast.walk(tree):
            if isinstance(node, ast.Try):
                if node.handlers:
                    patterns.append('try_except')
                if node.finalbody:
                    patterns.append('try_finally')
            elif isinstance(node, ast.Raise):
                patterns.append('explicit_raise')
            elif isinstance(node, ast.Assert):
                patterns.append('assertion')
    
    def _has_type_hints(self, tree: ast.AST) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç±»å‹æç¤º"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.returns or any(arg.annotation for arg in node.args.args):
                    return True
        return False
    
    def _analyze_async_patterns(self, tree: ast.AST, patterns: list[str]):
        """åˆ†æå¼‚æ­¥æ¨¡å¼"""
        for node in ast.walk(tree):
            if isinstance(node, ast.AsyncFunctionDef):
                patterns.append('async_function')
            elif isinstance(node, ast.Await):
                patterns.append('await_usage')
            elif isinstance(node, ast.AsyncWith):
                patterns.append('async_context_manager')
    
    async def _extract_code_patterns(self, project_path: Path) -> list[CodePattern]:
        """æå–ä»£ç æ¨¡å¼"""
        patterns = []
        
        # æ‰«æPythonæ–‡ä»¶å¯»æ‰¾å¸¸è§æ¨¡å¼
        python_files = list(project_path.rglob('*.py'))[:30]  # é™åˆ¶æ–‡ä»¶æ•°é‡
        
        for py_file in python_files:
            try:
                content = py_file.read_text(encoding='utf-8')
                
                # æ£€æµ‹è®¾è®¡æ¨¡å¼
                self._detect_design_patterns(content, py_file, patterns)
                
                # æ£€æµ‹APIæ¨¡å¼
                self._detect_api_patterns_in_file(content, py_file, patterns)
                
                # æ£€æµ‹æ•°æ®å¤„ç†æ¨¡å¼
                self._detect_data_patterns(content, py_file, patterns)
                
            except Exception as e:
                logger.warning(f"æå–æ¨¡å¼å¤±è´¥ {py_file}: {e}")
                continue
        
        return patterns
    
    def _detect_design_patterns(self, content: str, file_path: Path, patterns: list[CodePattern]):
        """æ£€æµ‹è®¾è®¡æ¨¡å¼"""
        # Singletonæ¨¡å¼
        if 'def __new__' in content and '_instance' in content:
            patterns.append(CodePattern(
                pattern_type="Singleton",
                description="å•ä¾‹æ¨¡å¼å®ç°",
                example_code=self._extract_class_code(content, 'singleton'),
                file_path=str(file_path)
            ))
        
        # Factoryæ¨¡å¼
        if re.search(r'def create.*\(.*\):', content):
            patterns.append(CodePattern(
                pattern_type="Factory",
                description="å·¥å‚æ¨¡å¼å®ç°",
                example_code=self._extract_function_code(content, 'create'),
                file_path=str(file_path)
            ))
        
        # Dependency Injectionæ¨¡å¼
        if 'Depends(' in content or '@inject' in content:
            patterns.append(CodePattern(
                pattern_type="DependencyInjection",
                description="ä¾èµ–æ³¨å…¥æ¨¡å¼",
                example_code=self._extract_dependency_code(content),
                file_path=str(file_path)
            ))
    
    def _detect_api_patterns_in_file(self, content: str, file_path: Path, patterns: list[CodePattern]):
        """æ£€æµ‹APIæ¨¡å¼"""
        # FastAPIè·¯ç”±æ¨¡å¼
        if '@router.' in content or '@app.' in content:
            patterns.append(CodePattern(
                pattern_type="APIRouter",
                description="APIè·¯ç”±å®šä¹‰æ¨¡å¼",
                example_code=self._extract_route_code(content),
                file_path=str(file_path)
            ))
        
        # ä¸­é—´ä»¶æ¨¡å¼
        if 'middleware' in content.lower():
            patterns.append(CodePattern(
                pattern_type="Middleware",
                description="ä¸­é—´ä»¶æ¨¡å¼",
                example_code=self._extract_middleware_code(content),
                file_path=str(file_path)
            ))
    
    def _detect_data_patterns(self, content: str, file_path: Path, patterns: list[CodePattern]):
        """æ£€æµ‹æ•°æ®å¤„ç†æ¨¡å¼"""
        # Pydanticæ¨¡å‹æ¨¡å¼
        if 'BaseModel' in content:
            patterns.append(CodePattern(
                pattern_type="PydanticModel",
                description="Pydanticæ•°æ®æ¨¡å‹",
                example_code=self._extract_model_code(content),
                file_path=str(file_path)
            ))
        
        # æ•°æ®åº“ORMæ¨¡å¼
        if 'declarative_base' in content or 'Table' in content:
            patterns.append(CodePattern(
                pattern_type="ORMModel",
                description="ORMæ•°æ®æ¨¡å‹",
                example_code=self._extract_orm_code(content),
                file_path=str(file_path)
            ))
    
    def _extract_class_code(self, content: str, keyword: str) -> str:
        """æå–ç±»å®šä¹‰ä»£ç """
        lines = content.splitlines()
        for i, line in enumerate(lines):
            if line.strip().startswith('class ') and keyword.lower() in line.lower():
                # æå–æ•´ä¸ªç±»å®šä¹‰
                class_lines = [line]
                indent = len(line) - len(line.lstrip())
                for j in range(i + 1, len(lines)):
                    if lines[j].strip() == '':
                        class_lines.append(lines[j])
                    elif len(lines[j]) - len(lines[j].lstrip()) > indent:
                        class_lines.append(lines[j])
                    else:
                        break
                return '\n'.join(class_lines[:20])  # é™åˆ¶è¡Œæ•°
        return ""
    
    def _extract_function_code(self, content: str, keyword: str) -> str:
        """æå–å‡½æ•°å®šä¹‰ä»£ç """
        lines = content.splitlines()
        for i, line in enumerate(lines):
            if line.strip().startswith('def ') and keyword in line:
                func_lines = [line]
                indent = len(line) - len(line.lstrip())
                for j in range(i + 1, len(lines)):
                    if lines[j].strip() == '':
                        func_lines.append(lines[j])
                    elif len(lines[j]) - len(lines[j].lstrip()) > indent:
                        func_lines.append(lines[j])
                    else:
                        break
                return '\n'.join(func_lines[:15])  # é™åˆ¶è¡Œæ•°
        return ""
    
    def _extract_dependency_code(self, content: str) -> str:
        """æå–ä¾èµ–æ³¨å…¥ç›¸å…³ä»£ç """
        lines = content.splitlines()
        result_lines = []
        for line in lines:
            if 'Depends(' in line or '@inject' in line:
                result_lines.append(line)
        return '\n'.join(result_lines[:10])
    
    def _extract_route_code(self, content: str) -> str:
        """æå–è·¯ç”±å®šä¹‰ä»£ç """
        lines = content.splitlines()
        result_lines = []
        for i, line in enumerate(lines):
            if '@router.' in line or '@app.' in line:
                result_lines.append(line)
                # æ·»åŠ å‡½æ•°å®šä¹‰
                if i + 1 < len(lines):
                    result_lines.append(lines[i + 1])
        return '\n'.join(result_lines[:15])
    
    def _extract_middleware_code(self, content: str) -> str:
        """æå–ä¸­é—´ä»¶ä»£ç """
        lines = content.splitlines()
        result_lines = []
        for line in lines:
            if 'middleware' in line.lower():
                result_lines.append(line)
        return '\n'.join(result_lines[:10])
    
    def _extract_model_code(self, content: str) -> str:
        """æå–æ¨¡å‹å®šä¹‰ä»£ç """
        return self._extract_class_code(content, 'BaseModel')
    
    def _extract_orm_code(self, content: str) -> str:
        """æå–ORMæ¨¡å‹ä»£ç """
        return self._extract_class_code(content, 'Table')
    
    def _analyze_best_practices(self, project_path: Path, code_patterns: list[CodePattern]) -> list[str]:
        """åˆ†ææœ€ä½³å®è·µ"""
        practices = []
        
        # åŸºäºä»£ç æ¨¡å¼æ¨æ–­æœ€ä½³å®è·µ
        pattern_types = [p.pattern_type for p in code_patterns]
        
        if 'DependencyInjection' in pattern_types:
            practices.append("ä½¿ç”¨ä¾èµ–æ³¨å…¥æé«˜ä»£ç å¯æµ‹è¯•æ€§")
        
        if 'PydanticModel' in pattern_types:
            practices.append("ä½¿ç”¨Pydanticè¿›è¡Œæ•°æ®éªŒè¯")
        
        if 'APIRouter' in pattern_types:
            practices.append("ä½¿ç”¨è·¯ç”±å™¨ç»„ç»‡APIç«¯ç‚¹")
        
        # æ£€æŸ¥æ–‡æ¡£
        if any((project_path / f).exists() for f in ['README.md', 'docs']):
            practices.append("ç»´æŠ¤è¯¦ç»†çš„é¡¹ç›®æ–‡æ¡£")
        
        # æ£€æŸ¥æµ‹è¯•
        if any(p.name.startswith('test') for p in project_path.rglob('*.py')):
            practices.append("ç¼–å†™comprehensiveæµ‹è¯•")
        
        # æ£€æŸ¥é…ç½®ç®¡ç†
        if (project_path / 'config').exists() or any('config' in str(p) for p in project_path.rglob('*.py')):
            practices.append("é›†ä¸­ç®¡ç†é…ç½®")
        
        return practices
    
    def _extract_common_utilities(self, project_path: Path) -> list[str]:
        """æå–å¸¸ç”¨å·¥å…·å‡½æ•°"""
        utilities = []
        
        utils_dirs = ['utils', 'helpers', 'common', 'core']
        for utils_dir in utils_dirs:
            utils_path = project_path / utils_dir
            if utils_path.exists():
                for py_file in utils_path.rglob('*.py'):
                    utilities.append(f"{utils_dir}/{py_file.name}")
        
        return utilities
    
    def _extract_api_patterns(self, project_path: Path) -> list[str]:
        """æå–APIæ¨¡å¼"""
        patterns = []
        
        # æŸ¥æ‰¾APIç›¸å…³æ–‡ä»¶
        api_files = list(project_path.rglob('*api*.py')) + list(project_path.rglob('*router*.py'))
        
        for api_file in api_files[:10]:  # é™åˆ¶æ–‡ä»¶æ•°é‡
            try:
                content = api_file.read_text()
                if 'async def' in content:
                    patterns.append("å¼‚æ­¥APIç«¯ç‚¹")
                if 'StreamingResponse' in content:
                    patterns.append("æµå¼å“åº”")
                if 'HTTPException' in content:
                    patterns.append("HTTPå¼‚å¸¸å¤„ç†")
                if 'middleware' in content.lower():
                    patterns.append("APIä¸­é—´ä»¶")
            except Exception:
                continue
        
        return list(set(patterns))
    
    def _extract_error_handling_strategies(self, project_path: Path) -> list[str]:
        """æå–é”™è¯¯å¤„ç†ç­–ç•¥"""
        strategies = []
        
        python_files = list(project_path.rglob('*.py'))[:20]
        for py_file in python_files:
            try:
                content = py_file.read_text()
                if 'logging' in content:
                    strategies.append("ç»“æ„åŒ–æ—¥å¿—è®°å½•")
                if 'HTTPException' in content:
                    strategies.append("HTTPå¼‚å¸¸å¤„ç†")
                if 'ValidationError' in content:
                    strategies.append("æ•°æ®éªŒè¯é”™è¯¯å¤„ç†")
                if 'try:' in content and 'except' in content:
                    strategies.append("å¼‚å¸¸æ•è·å’Œå¤„ç†")
            except Exception:
                continue
        
        return list(set(strategies))
    
    def _extract_testing_patterns(self, project_path: Path) -> list[str]:
        """æå–æµ‹è¯•æ¨¡å¼"""
        patterns = []
        
        test_files = list(project_path.rglob('test_*.py')) + list(project_path.rglob('*_test.py'))
        
        for test_file in test_files[:10]:
            try:
                content = test_file.read_text()
                if 'pytest' in content:
                    patterns.append("pytestæµ‹è¯•æ¡†æ¶")
                if 'mock' in content.lower():
                    patterns.append("æ¨¡æ‹Ÿå¯¹è±¡æµ‹è¯•")
                if 'fixture' in content:
                    patterns.append("æµ‹è¯•å¤¹å…·")
                if 'async def test_' in content:
                    patterns.append("å¼‚æ­¥æµ‹è¯•")
            except Exception:
                continue
        
        return list(set(patterns))
    
    def _extract_deployment_patterns(self, project_path: Path) -> list[str]:
        """æå–éƒ¨ç½²æ¨¡å¼"""
        patterns = []
        
        if (project_path / 'Dockerfile').exists():
            patterns.append("Dockerå®¹å™¨åŒ–")
        
        if (project_path / 'docker-compose.yml').exists():
            patterns.append("Docker Composeç¼–æ’")
        
        if (project_path / '.github' / 'workflows').exists():
            patterns.append("GitHub Actions CI/CD")
        
        if (project_path / 'requirements.txt').exists():
            patterns.append("pipä¾èµ–ç®¡ç†")
        
        if (project_path / 'pyproject.toml').exists():
            patterns.append("ç°ä»£Pythoné¡¹ç›®ç»“æ„")
        
        return patterns
    
    def get_analysis_summary(self, analysis: ReferenceProjectAnalysis) -> str:
        """è·å–åˆ†ææ‘˜è¦"""
        summary_parts = [
            f"ğŸ“¦ é¡¹ç›®: {analysis.project_name}",
            f"ğŸ—ï¸ æ¶æ„: {', '.join([p.value for p in analysis.tech_stack.architecture_patterns])}",
            f"ğŸ› ï¸ æ¡†æ¶: {', '.join([f.value for f in analysis.tech_stack.frameworks])}",
            f"ğŸ“ ä»£ç æ¨¡å¼: {len(analysis.code_patterns)} ä¸ª",
            f"âœ¨ æœ€ä½³å®è·µ: {len(analysis.best_practices)} ä¸ª",
            f"ğŸ”§ å·¥å…·å‡½æ•°: {len(analysis.common_utilities)} ä¸ª"
        ]
        
        return '\n'.join(summary_parts) 

    async def analyze_projects(self) -> dict[str, dict[str, Any]]:
        """åˆ†ææ‰€æœ‰æ£€æµ‹åˆ°çš„å‚è€ƒé¡¹ç›®"""
        results = {}
        
        # æ£€æµ‹å‚è€ƒé¡¹ç›®
        reference_projects = self.detect_reference_projects()
        
        if not reference_projects:
            logger.info("ğŸ“­ æœªæ£€æµ‹åˆ°å‚è€ƒé¡¹ç›®")
            return results
        
        logger.info(f"ğŸ” æ£€æµ‹åˆ° {len(reference_projects)} ä¸ªå‚è€ƒé¡¹ç›®: {', '.join(reference_projects)}")
        
        for project_name in reference_projects:
            try:
                logger.info(f"ğŸ” å¼€å§‹åˆ†æå‚è€ƒé¡¹ç›®: {project_name}")
                analysis = await self.analyze_project(project_name)
                
                # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼
                project_data = {
                    'name': analysis.project_name,
                    'path': analysis.project_path,
                    'frameworks': [f.value for f in analysis.tech_stack.frameworks],
                    'patterns': [p.value for p in analysis.tech_stack.architecture_patterns],
                    'dependencies': analysis.tech_stack.dependencies,
                    'python_version': analysis.tech_stack.python_version,
                    'best_practices': analysis.best_practices,
                    'code_patterns': [
                        {
                            'type': pattern.pattern_type,
                            'description': pattern.description,
                            'example': pattern.example_code,
                            'file_path': pattern.file_path,
                            'frequency': pattern.frequency
                        }
                        for pattern in analysis.code_patterns
                    ],
                    'coding_guidelines': [
                        "éµå¾ªPEP 8é£æ ¼è§„èŒƒ",
                        "ä½¿ç”¨ç±»å‹æç¤º" if analysis.coding_style.type_hints_usage else "è€ƒè™‘æ·»åŠ ç±»å‹æç¤º",
                        f"æ–‡æ¡£é£æ ¼: {analysis.coding_style.documentation_style}",
                        *analysis.coding_style.import_patterns[:3],
                        *analysis.coding_style.error_handling_patterns[:3]
                    ],
                    'architecture_insights': [
                        f"é¡¹ç›®é‡‡ç”¨ {', '.join([p.value for p in analysis.tech_stack.architecture_patterns])} æ¶æ„æ¨¡å¼",
                        f"ä¸»è¦æŠ€æœ¯æ ˆ: {', '.join([f.value for f in analysis.tech_stack.frameworks])}",
                        f"åŒ…å« {len(analysis.code_patterns)} ç§ä»£ç æ¨¡å¼",
                        *analysis.api_patterns[:2],
                        *analysis.testing_patterns[:2]
                    ],
                    'common_utilities': analysis.common_utilities,
                    'api_patterns': analysis.api_patterns,
                    'error_handling_strategies': analysis.error_handling_strategies,
                    'testing_patterns': analysis.testing_patterns,
                    'deployment_patterns': analysis.deployment_patterns
                }
                
                results[project_name] = project_data
                
                # æ‰“å°åˆ†ææ‘˜è¦
                summary = self.get_analysis_summary(analysis)
                logger.info(f"âœ… å®Œæˆé¡¹ç›®åˆ†æ:\n{summary}")
                
            except Exception as e:
                logger.error(f"âŒ åˆ†æé¡¹ç›® {project_name} å¤±è´¥: {e}")
                # ç»§ç»­åˆ†æå…¶ä»–é¡¹ç›®
                continue
        
        if results:
            logger.info(f"ğŸ‰ æˆåŠŸåˆ†æäº† {len(results)} ä¸ªå‚è€ƒé¡¹ç›®")
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æˆåŠŸåˆ†æä»»ä½•å‚è€ƒé¡¹ç›®")
        
        return results 