"""LLM å·¥å…·æ¨¡å—

æä¾›ä¸ OpenAI API çš„äº¤äº’åŠŸèƒ½ã€‚
"""

import logging
from typing import Dict, Any, List
from openai import AsyncOpenAI
import httpx
from .config import LLM_CONFIG

logger = logging.getLogger(__name__)

class LLMManager:
    """LLM ç®¡ç†å™¨"""
    
    def __init__(self, api_key: str, proxy_url: str = None, max_retries: int = 3):
        """åˆå§‹åŒ– LLM ç®¡ç†å™¨
        
        Args:
            api_key: OpenAI API å¯†é’¥
            proxy_url: ä»£ç†URLï¼Œæ ¼å¼å¦‚ http://127.0.0.1:7890
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        # é…ç½®HTTPå®¢æˆ·ç«¯ï¼Œæ”¯æŒä»£ç†å’Œé‡è¯•
        http_client = None
        if proxy_url:
            http_client = httpx.AsyncClient(
                proxy=proxy_url,
                timeout=60.0
            )
            logger.info(f"ä½¿ç”¨ä»£ç†: {proxy_url}")
        
        self.client = AsyncOpenAI(
            api_key=api_key,
            http_client=http_client,
            max_retries=max_retries
        )
        self.max_retries = max_retries
        logger.info("åˆå§‹åŒ– LLM ç®¡ç†å™¨")
    
    async def analyze_requirements(self, requirements: str) -> List[Dict[str, str]]:
        """åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œç”Ÿæˆ Issue åˆ—è¡¨
        
        Args:
            requirements: ç”¨æˆ·éœ€æ±‚æè¿°
            
        Returns:
            Issue åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ” åˆ†æç”¨æˆ·éœ€æ±‚: {requirements}")
            
            response = await self.client.chat.completions.create(
                model=LLM_CONFIG["model"],
                messages=[
                    {
                        "role": "system", 
                        "content": """ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚åˆ†æå¸ˆï¼Œè´Ÿè´£å°†ç”¨æˆ·éœ€æ±‚åˆ†è§£ä¸ºå…·ä½“çš„å¼€å‘ä»»åŠ¡ã€‚

è¯·å°†ç”¨æˆ·éœ€æ±‚åˆ†è§£ä¸º3-5ä¸ªå…·ä½“çš„å¼€å‘ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡åº”è¯¥ï¼š
1. æœ‰æ˜ç¡®çš„æ ‡é¢˜
2. æœ‰è¯¦ç»†çš„æè¿°
3. æ˜¯å¯ä»¥ç‹¬ç«‹å®Œæˆçš„åŠŸèƒ½

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š
[
  {
    "title": "ä»»åŠ¡æ ‡é¢˜",
    "description": "è¯¦ç»†çš„ä»»åŠ¡æè¿°ï¼ŒåŒ…æ‹¬å…·ä½“è¦å®ç°çš„åŠŸèƒ½ã€æŠ€æœ¯è¦æ±‚ç­‰"
  },
  ...
]"""
                    },
                    {
                        "role": "user", 
                        "content": f"è¯·å°†ä»¥ä¸‹éœ€æ±‚åˆ†è§£ä¸ºå…·ä½“çš„å¼€å‘ä»»åŠ¡ï¼š\n\n{requirements}"
                    }
                ],
                temperature=LLM_CONFIG["temperature"],
                max_tokens=LLM_CONFIG["max_tokens"]
            )
            
            content = response.choices[0].message.content.strip()
            logger.info(f"ğŸ¤– GPTå“åº”: {content}")
            
            # è§£æJSONå“åº”
            import json
            import re
            
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                issues_data = json.loads(json_str)
                
                issues = []
                for item in issues_data:
                    if isinstance(item, dict) and 'title' in item and 'description' in item:
                        issues.append({
                            'title': item['title'],
                            'description': item['description']
                        })
                
                logger.info(f"âœ… æˆåŠŸè§£æå‡º {len(issues)} ä¸ªä»»åŠ¡")
                return issues
            else:
                logger.warning("âŒ æ— æ³•ä»å“åº”ä¸­æå–JSONæ ¼å¼çš„ä»»åŠ¡åˆ—è¡¨")
                
                # Fallback: æ‰‹åŠ¨è§£æ
                lines = content.split('\n')
                issues = []
                current_title = None
                current_desc = []
                
                for line in lines:
                    line = line.strip()
                    if line.startswith('1.') or line.startswith('2.') or line.startswith('3.') or \
                       line.startswith('4.') or line.startswith('5.') or line.startswith('-'):
                        if current_title:
                            issues.append({
                                'title': current_title,
                                'description': ' '.join(current_desc)
                            })
                        current_title = re.sub(r'^[\d\-\.\s]+', '', line)
                        current_desc = []
                    elif line and current_title:
                        current_desc.append(line)
                
                if current_title:
                    issues.append({
                        'title': current_title,
                        'description': ' '.join(current_desc)
                    })
                
                logger.info(f"âœ… Fallbackè§£æå‡º {len(issues)} ä¸ªä»»åŠ¡")
            return issues
                
        except Exception as e:
            logger.error(f"âŒ åˆ†æéœ€æ±‚æ—¶å‡ºé”™: {e}")
            # è¿”å›ä¸€ä¸ªé»˜è®¤ä»»åŠ¡
            return [{
                'title': f"å®ç°ç”¨æˆ·éœ€æ±‚: {requirements[:50]}...",
                'description': f"ç”¨æˆ·éœ€æ±‚: {requirements}\n\nè¯·æ ¹æ®ä¸Šè¿°éœ€æ±‚å®ç°ç›¸åº”åŠŸèƒ½ã€‚"
            }]
    
    async def review_code(self, issue: Dict[str, Any], code: str) -> Dict[str, Any]:
        """å®¡æŸ¥ä»£ç æäº¤
        
        Args:
            issue: Issue ä¿¡æ¯
            code: æäº¤çš„ä»£ç 
            
        Returns:
            å®¡æŸ¥ç»“æœ
        """
        try:
            response = await self.client.chat.completions.create(
                model=LLM_CONFIG["model"],
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä»£ç å®¡æŸ¥å‘˜ï¼Œè´Ÿè´£å®¡æŸ¥ä»£ç è´¨é‡å’ŒåŠŸèƒ½å®Œæ•´æ€§ã€‚"},
                    {"role": "user", "content": f"""è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼š

Issue: {issue['title']}
æè¿°: {issue['description']}

ä»£ç :
```python
{code}
```

è¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
1. ä»£ç æ˜¯å¦æ»¡è¶³ Issue è¦æ±‚
2. ä»£ç è´¨é‡è¯„ä¼°
3. æ”¹è¿›å»ºè®®
4. æ˜¯å¦é€šè¿‡å®¡æŸ¥"""}
                ],
                temperature=LLM_CONFIG["temperature"],
                max_tokens=LLM_CONFIG["max_tokens"]
            )
            
            # è§£æå“åº”
            content = response.choices[0].message.content
            # ç®€å•çš„å®¡æŸ¥é€»è¾‘ï¼šå¦‚æœç”Ÿæˆäº†ä»£ç å°±é€šè¿‡
            approved = len(code.strip()) > 50  # ä»£ç é•¿åº¦å¤§äº50å­—ç¬¦å°±è®¤ä¸ºé€šè¿‡
            logger.info(f"å®¡æŸ¥ Issue {issue['id']} çš„ä»£ç ")
            return {"approved": approved, "comments": content}
        except Exception as e:
            logger.error(f"å®¡æŸ¥ä»£ç æ—¶å‡ºé”™: {e}")
            return {"approved": False, "comments": str(e)}
    
    async def generate_code(self, issue: Dict[str, Any]) -> str:
        """ç”Ÿæˆä»£ç å®ç°
        
        Args:
            issue: Issue ä¿¡æ¯
            
        Returns:
            ç”Ÿæˆçš„ä»£ç 
        """
        try:
            logger.info(f"ğŸ¤– ä¸ºIssue {issue['id']} è°ƒç”¨GPTç”Ÿæˆä»£ç ")
            
            title = issue.get('title', '')
            description = issue.get('description', '')
            
            logger.info(f"ğŸ“‹ Issueæ ‡é¢˜: {title}")
            logger.info(f"ğŸ“ Issueæè¿°: {description}")
            
            # æ„å»ºè¯¦ç»†çš„GPT prompt
            prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„Pythonä»£ç ï¼š

æ ‡é¢˜: {title}
è¯¦ç»†æè¿°: {description}

è¦æ±‚ï¼š
1. ç”Ÿæˆå®Œæ•´ã€å¯è¿è¡Œçš„Pythonä»£ç 
2. åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šå’Œæ–‡æ¡£å­—ç¬¦ä¸²
3. ä»£ç ç»“æ„æ¸…æ™°ï¼Œéµå¾ªPythonæœ€ä½³å®è·µ
4. åŒ…å«é€‚å½“çš„é”™è¯¯å¤„ç†
5. å¦‚æœéœ€è¦å¤–éƒ¨åº“ï¼Œè¯·åœ¨ä»£ç å¼€å¤´æ³¨é‡Šè¯´æ˜
6. æä¾›ä½¿ç”¨ç¤ºä¾‹æˆ–æµ‹è¯•ä»£ç 
7. ç¡®ä¿ä»£ç çš„å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§

è¯·ç›´æ¥è¿”å›Pythonä»£ç ï¼Œä¸è¦åŒ…å«ä»»ä½•markdownæ ¼å¼æ ‡è®°ï¼š"""

            # è°ƒç”¨GPT APIç”Ÿæˆä»£ç 
            response = await self.client.chat.completions.create(
                model=LLM_CONFIG["model"],
                messages=[
                    {
                        "role": "system", 
                        "content": "ä½ æ˜¯ä¸€ä¸ªèµ„æ·±çš„Pythonå¼€å‘å·¥ç¨‹å¸ˆï¼Œæ“…é•¿æ ¹æ®éœ€æ±‚ç¼–å†™é«˜è´¨é‡ã€å®Œæ•´ã€å¯è¿è¡Œçš„Pythonä»£ç ã€‚ä½ çš„ä»£ç åº”è¯¥å…·æœ‰è‰¯å¥½çš„ç»“æ„ã€æ¸…æ™°çš„æ³¨é‡Šã€é€‚å½“çš„é”™è¯¯å¤„ç†ï¼Œå¹¶éµå¾ªPythonæœ€ä½³å®è·µã€‚"
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=LLM_CONFIG["temperature"],
                max_tokens=LLM_CONFIG["max_tokens"]
            )
            
            generated_code = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„markdownæ ¼å¼
            if generated_code.startswith("```python"):
                generated_code = generated_code[9:].strip()
            elif generated_code.startswith("```"):
                generated_code = generated_code[3:].strip()
            
            if generated_code.endswith("```"):
                generated_code = generated_code[:-3].strip()
            
            # éªŒè¯ç”Ÿæˆçš„ä»£ç ä¸ä¸ºç©º
            if not generated_code or len(generated_code.strip()) < 10:
                raise ValueError("GPTç”Ÿæˆçš„ä»£ç ä¸ºç©ºæˆ–è¿‡çŸ­")
            
            logger.info(f"âœ… GPTä»£ç ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(generated_code)} å­—ç¬¦")
            logger.info(f"ğŸ“Š ä»£ç è¡Œæ•°: {len(generated_code.splitlines())} è¡Œ")
            
            return generated_code
            
        except Exception as e:
            logger.error(f"âŒ GPTä»£ç ç”Ÿæˆå¤±è´¥: {e}")
            
            # ä¸ä½¿ç”¨æ¨¡æ¿ï¼Œç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯å’ŒåŸºç¡€ä»£ç æ¡†æ¶
            error_code = f'''"""
ä»£ç ç”Ÿæˆå¤±è´¥

Issue: {title}
æè¿°: {description}
é”™è¯¯: {str(e)}

è¯·æ‰‹åŠ¨å®ç°æ­¤åŠŸèƒ½ï¼Œæˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•ã€‚
"""

# TODO: å®ç° {title}
# æè¿°: {description}

def main():
    """ä¸»å‡½æ•° - è¯·æ ¹æ®éœ€æ±‚å®ç°å…·ä½“åŠŸèƒ½"""
    print("æ­¤ä»£ç éœ€è¦æ‰‹åŠ¨å®ç°")
    print("Issue: {title}")
    print("æè¿°: {description}")
    print("é”™è¯¯ä¿¡æ¯: {str(e)}")
    
    # åœ¨è¿™é‡Œæ·»åŠ ä½ çš„å®ç°
    pass

if __name__ == "__main__":
    main()
'''
            logger.warning(f"ğŸ”„ è¿”å›åŸºç¡€ä»£ç æ¡†æ¶ï¼Œç”¨æˆ·éœ€è¦æ‰‹åŠ¨å®ç°")
            return error_code 